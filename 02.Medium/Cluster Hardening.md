[>> вернуться на главную страницу](https://github.com/BEPb/tryhackme/blob/master/README.md)

# Комната [Cluster Hardening](https://tryhackme.com/r/room/clusterhardening) 

Всего 8 заданий:
## Задание 1
Приглашаем всех пользователей Kubernetes и начинающих инженеров DevSecOps! Вы знакомы с Kubernetes, концепциями, 
архитектурой, ландшафтом, но хотите узнать, как безопасно построить свой кластер K8s, как настоящий инженер 
DevSecOps? Что ж, вы попали по адресу. В этой комнате вы узнаете о вопросах безопасности при начале разработки 
своего кластера Kubernetes, с подробными объяснениями, примерами и, в последнем задании, практической виртуальной 
машиной, имитирующей «день из жизни» инженера DevSecOps.

Предпосылки обучения

Эта комната предполагает наличие некоторых базовых знаний о Kubernetes; предполагаемые знания изложены в нашей 
комнате Intro to Kubernetes  , поэтому обязательно ознакомьтесь с ней перед началом. Также предполагается, что у вас 
есть базовые знания о технологиях, поддерживающих Kubernetes, которые изложены в таких комнатах, как Intro to 
Containerisation и Intro to Docker . Для обсуждения сетевой безопасности предполагается наличие некоторых базовых 
знаний об асимметричном шифровании и TLS; эти знания можно найти в Intro to Cryptography.


Цели обучения 
- Понять концепцию кластерного упрочнения 
- Узнайте, как защитить сетевой трафик в кластере Kubernetes.
- Узнайте, как защитить компонент Kubelet в кластере Kubernetes.
- Узнайте, как защитить трафик API в кластере Kubernetes.
- Понимание контрольных показателей безопасности и их использования в Kubernetes

### Ответьте на вопросы ниже
Нажмите «Завершить», чтобы продолжить свое путешествие по DevSecOps.

```commandline
Ответ не нужен
```

## Задание 2
Добро пожаловать! Kubernetes Laboratories создает кластер Kubernetes для поддержки своего предстоящего релиза и 
нуждается в инженере DevSecOps для этой работы. Думаю, вы справитесь с этой задачей. Этот кластер должен быть создан 
с использованием методов укрепления кластера, но что вы имеете в виду?

Что такое кластерное упрочнение ?

Как вы помните, кластер Kubernetes содержит узлы, а Kubernetes запускает рабочую нагрузку, помещая контейнеры в 
модули, которые работают на этих узлах. Итак, проще говоря, кластер Kubernetes находится на самом высоком уровне 
нашей архитектуры Kubernetes и включает в себя все компоненты нижнего уровня. Со всеми этими различными компонентами,
которые общаются друг с другом, имеют конфигурации по умолчанию и т. д., появляется много поверхности. Эта 
поверхность по умолчанию может быть уязвима для атак/эксплуатации или иметь конфигурации по умолчанию, которые были 
бы безвредны в небольшой контролируемой/локальной среде, но при наличии в кластере для крупной организации, которая 
обрабатывает критически важные для бизнеса операции, не говоря уже о обработке высококонфиденциальных данных 
клиентов, это может стать проблемой. Усиление кластера — это практика обеспечения того, чтобы ваш кластер Kubernetes 
имел как можно меньше таких уязвимостей, конфигураций по умолчанию и как можно больше безопасных практик.

Значок усиления кластера

Безопасность прежде всего!

Мышление «Безопасность прежде всего» всегда полезно в мире кибербезопасности, и при работе с такой технологией, как 
Kubernetes, это ничем не отличается. Внедрение этих методов укрепления кластера с момента настройки обеспечивает 
безопасность вашей среды k8s, а также избавляет от головной боли в дальнейшем процессе разработки. Как инженер 
DevSecOps, вы, скорее всего, не создадите ни одного кластера Kubernetes в свое время, а много. Изучение этих методов 
укрепления кластера может гарантировать, что у вас будут последовательные и безопасные привычки во всех кластерах 
Kubernetes, которые вы реализуете. В ходе этой комнаты мы рассмотрим некоторые методы укрепления кластера, которые 
вы можете учитывать при реализации своего кластера Kubernetes. Давайте приступим к работе!

безопасность первая графика

### Ответьте на вопросы ниже
Что находится на самом высоком уровне архитектуры Kubernetes и включает в себя все компоненты более низкого уровня?
```commandline
Kubernetes cluster
```

Какой образ мышления всегда приносит пользу в кибермире?
```commandline
Security-first
```

## Задание 3
Показатели безопасности СНГ

В предыдущей задаче мы обсудили, как внедрение лучших практик укрепления кластера Kubernetes может принести пользу 
среде Kubernetes за счет снижения уязвимостей и, следовательно, поверхности атаки. Однако лучшие практики укрепления 
кластера регулярно меняются по мере появления новых уязвимостей, удаления старых функций/введения новых функций и т. 
д., так как же нам быть в курсе того, что представляют собой эти практики? К счастью, этим занимается CIS (Центр 
интернет-безопасности), некоммерческая организация, которая помогает собирать и определять стандарты, которые могут 
быть реализованы в качестве превентивных мер против кибератак. Они определяют эти стандарты как «контрольные 
показатели безопасности»; таким образом, ваш кластер может быть проверен на соответствие этим контрольным 
показателям для проверки вашего уровня безопасности.

CIS предоставляет тесты безопасности для многих различных технологий (включая браузеры, базы данных и облачные 
технологии); мы обсудим некоторые тесты Kubernetes в этой комнате, но если вам интересно, вы можете ознакомиться с 
полным документом по тестированию, доступным здесь. Этот документ разделяет методы укрепления кластера на различные 
компоненты Kubernetes, каждый из которых предоставляет метод аудита и исправления. Тесты безопасности CIS являются 
лишь одним примером базового ресурса кибербезопасности; он является одним из наиболее часто используемых наряду с 
STIG (руководства по технической информации по безопасности), предоставляемыми DISA (Агентство систем Министерства 
обороны США).

значок теста безопасности

Некоторые примеры тестов безопасности CIS Kubernetes: 

Для API- сервера: 1.2.25 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate 
(Это будет сделано во время настройки шифрования трафика API , подробнее об этом в Задаче 5)

Для компонента Kubelet: 4.2.1 Ensure that the --anonymous-auth argument is set to false  (если оставить значение 
«true», kubelet разрешит анонимный трафик; подробнее об этом в Задаче 4)

Для сетевых политик: 5.3.2 Ensure that all Namespaces have Network Policies defined  (По умолчанию не будет никаких 
сетевых политик, ограничивающих связь между модулями; подробнее об этом в Задаче 7)

#### Kube-bench 

«Лучший способ внедрения мер безопасности — это просмотреть 300-страничный документ страница за страницей», — никто 
никогда не говорил. Именно по этой причине был создан инструмент с открытым исходным кодом «Kube-bench». Этот 
инструмент, разработанный Aqua Security, может выполнять автоматизированные оценки для проверки того, был ли 
реализован Kubernetes с использованием лучших методов укрепления кластера. Это больше похоже на правду! Kube-bench 
можно установить несколькими способами, вот некоторые из них:
- Kube-bench можно запустить внутри модуля, но для доступа к определенным каталогам/файлам конфигурации и 
  пространству имен PID хоста (пространство имен идентификаторов процессов для проверки запущенных процессов)   
  потребуются достаточные разрешения.
- Запустить внутри контейнера
- Запуск в сервисе облачного провайдера, например Azure AKS (Azure Kubernetes Service) или Amazon EKS (Elastic 
  Kubernetes Service) 
Некоторые моменты, которые следует учитывать при использовании Kube-bench для обеспечения соответствия требованиям 
  безопасности кластера: Между выпусками Kubernetes и CIS-тестов безопасности нет однозначного соответствия, то есть 
  при выходе новой версии Kubernetes выпуск CIS-теста безопасности, в котором подробно описываются новые тесты, 
  которые должны быть выполнены в этой версии, НЕ выпускается. Вместо этого тесты безопасности CIS могут охватывать 
  несколько выпусков Kubernetes одновременно; какие тесты безопасности CIS охватывают какие выпуски Kubernetes, 
  можно проверить здесь . Kube-bench по умолчанию пытается определить запущенную версию Kubernetes и сопоставить ее 
  с соответствующей версией теста безопасности CIS , что немного упрощает жизнь.

После настройки Kube-bench на вашем кластере Kubernetes, вот пример того, как может выглядеть вывод. Эти проверки 
помогают определить области интереса при усилении кластера, которые документ по бенчмарку безопасности CIS затем 
может помочь исправить:
```commandline
[INFO] 4 Worker Node Security Configuration
[INFO] 4.1 Worker Node Configuration Files
[FAIL] 4.1.1 Ensure that the kubelet service file permissions are set to 600 or more restrictive (Automated)
[PASS] 4.1.2 Ensure that the kubelet service file ownership is set to root:root (Automated)
[WARN] 4.1.3 If proxy kubeconfig file exists ensure permissions are set to 600 or more restrictive (Manual)
[WARN] 4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root (Manual)
[PASS] 4.1.5 Ensure that the --kubeconfig kubelet.conf file permissions are set to 600 or more restrictive (Automated)
[PASS] 4.1.6 Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root (Automated)
[WARN] 4.1.7 Ensure that the certificate authorities file permissions are set to 600 or more restrictive (Manual)
[WARN] 4.1.8 Ensure that the client certificate authorities file ownership is set to root:root (Manual)
[FAIL] 4.1.9 If the kubelet config.yaml configuration file is being used validate permissions set to 600 or more restrictive (Automated)
[PASS] 4.1.10 If the kubelet config.yaml configuration file is being used validate file ownership is set to root:root (Automated)
[INFO] 4.2 Kubelet
[PASS] 4.2.1 Ensure that the --anonymous-auth argument is set to false (Automated)
[PASS] 4.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)
[PASS] 4.2.3 Ensure that the --client-ca-file argument is set as appropriate (Automated)
[PASS] 4.2.4 Verify that the --read-only-port argument is set to 0 (Manual)
[PASS] 4.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Manual)
[PASS] 4.2.6 Ensure that the --make-iptables-util-chains argument is set to true (Automated)
[WARN] 4.2.7 Ensure that the --hostname-override argument is not set (Manual)
[PASS] 4.2.8 Ensure that the eventRecordQPS argument is set to a level which ensures appropriate event capture (Manual)
[WARN] 4.2.9 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Manual)
[PASS] 4.2.10 Ensure that the --rotate-certificates argument is not set to false (Automated)
[PASS] 4.2.11 Verify that the RotateKubeletServerCertificate argument is set to true (Manual)
[WARN] 4.2.12 Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers (Manual)
[WARN] 4.2.13 Ensure that a limit is set on pod PIDs (Manual)
```

### Ответьте на вопросы ниже
Какие стандарты используются для проверки уровня безопасности кластеров?
```commandline
security benchmarks
```
Какой стандарт безопасности CIS гарантирует запрет анонимного трафика? 
```commandline
4.2.1
```
Какой инструмент с открытым исходным кодом может выполнять автоматизированную оценку безопасности в кластере Kubernetes?
```commandline
Kube-bench
```

## Задание 4
Кубелет

Давайте вспомним компонент kubelet и его цель, прежде чем мы перейдем к последствиям безопасности, не так ли? 
Kubelet — это агент, который работает на каждом узле в кластере и отвечает за обеспечение работы контейнеров в поде. 
Kubelet работает с PodSpecs, PodSpec — это объект YAML или JSON , который определяет под. Kubelet принимает наборы 
PodSpecs, предоставленные через различные механизмы (включая apiserver, file или http endpoint, хотя в основном 
через механизм apiserver). Kubelet следит за тем, чтобы контейнеры, описанные в этих PodSpecs, были запущены и 
работоспособны (то есть этот компонент взаимодействует со средой выполнения контейнера).

Аспекты безопасности Kubelet

Компонент kubelet прослушивает запросы на следующих портах: 

Порт 10250: Здесь обслуживается kublet-api и обеспечивается полный доступ 

Порт 10255: где он обслуживает другой API, имеющий неавторизованный, неаутентифицированный доступ только для чтения.

Kubelet-api используется для управления контейнерами, запущенными на узле, и, как уже упоминалось, имеет полный 
доступ; это делает его главной целью для хакеров, которые могут использовать этот API для прямого взаимодействия с 
компонентом Kubelet и создания собственных контейнеров или удаления контейнеров, запущенных на рабочем узле. По этой 
причине крайне важно, чтобы вы, как инженер DevSecOps, обеспечили блокировку несанкционированного трафика.

Компонент kubelet должен реагировать только на трафик, исходящий от kube-apiserver. Это можно сделать, внеся 
изменения в конфигурацию файла конфигурации kubelet. Примечание: чтобы узнать, где находится файл конфигурации 
kubelet, запустите ps ef | grep kubelet и найдите каталог в --configфлаге. Первым шагом к блокировке 
несанкционированного трафика является отключение анонимного трафика (это реализует CIS security benchmark 4.2.1). Мы 
делаем это, устанавливая authentication:anonymous:enabled значение false. Вот так:
```commandline
apiVersion: kubelet.config.k8s.io/v1beta1
authentication: 
  anonymous: 
    enabled: false 
  webhook: 
    cacheTTL: 0s 
    enabled: true 
  x509: 
    clientCAFile: /var/lib/minikube/certs/ca.crt
```

Аутентификация с помощью Kubelet

Теперь, когда анонимный трафик ограничен, компонент kubelet должен будет аутентифицировать запрос. Это можно сделать 
одним из двух способов: 
- Аутентификация клиентского сертификата X509: Kubelet необходимо будет запустить с --client-ca-file флагом 
  (предоставляя пакет CA для аутентификации сертификатов), отдельно для этого метода компонент apiserver необходимо 
  будет запустить с флагами --kubelet-client-certificate и --kubelet-client-key.
- API Bearer Token: настраивается путем установки authentication:webhook:enabled в значение "true". Затем Kubelet 
  необходимо будет запустить с флагами--authentication-token-webhook и--kubeconfig. Группу APIauthentication.k8s.io/v1beta1 также необходимо будет включить на сервере API.

При реализации любого из этих методов аутентификации компонент kubelet больше не будет принимать запросы из 
неаутентифицированных источников, а кластер немного укрепится! Например, если была включена аутентификация 
сертификата и был сделан вызов к компоненту kubelet, пытающемуся составить список подов, он будет отклонен как 
«неавторизованный», если только вместе с запросом не будут предоставлены соответствующий ключ и сертификат. Это та 
практика, которую вы должны внедрять здесь, в Kubernetes Laboratories, как инженер DevSecOps.
### Ответьте на вопросы ниже
Какой порт Kubelet обслуживает kubelet-api и обеспечивает полный доступ?
```commandline
10250
```
Какое значение необходимо установить на «false», чтобы обеспечить  блокировку несанкционированного трафика?
```commandline
authentication:anonymous:enabled
```
Одним из методов аутентификации запросов kubelet является « Аутентификация клиентского сертификата X509». Какой 
другой метод? 
```commandline
API Bearer Token
```

## Задание 5
Первая линия обороны

В кластере Kubernetes есть много компонентов. Эти компоненты должны взаимодействовать; Kubernetes полностью 
управляется API, что означает, что ограничение этого взаимодействия (кто может получить к нему доступ, что они могут 
делать) должно быть первой линией обороны. Как инженер DevSecOps, вы должны реализовать эту первую линию обороны. 
Один из способов, с помощью которого мы можем защитить трафик API, — это шифрование. Эта задача предполагает базовые 
знания таких концепций, как асинхронное шифрование и шифрование TLS. Если эти концепции являются для вас слепым 
пятном или вам нужно освежить знания, посетите нашу комнату Введение в криптографию.

значок первой линии обороны


Понимание взаимодействия API Kubernetes

Kubernetes ожидает, что все коммуникации API в кластере будут зашифрованы по умолчанию, при этом большинство методов 
установки поддерживают создание и распространение сертификатов по компонентам кластера. Перед внедрением шифрования 
TLS и распространением сертификатов мы должны установить, действует ли компонент как клиент или сервер (или и то, и 
другое) при взаимодействии в кластере. Понимание этого поможет определить, какой сертификат следует сгенерировать 
для каждого компонента. Взгляните на следующие графики, на которых показаны различные «серверы» и «клиенты» в 
кластере Kubernetes: 

Диаграмма связи API


Kube-apiserver: Этот компонент действует как сервер при доступе внешних пользователей и других компонентов в 
кластере. Он также действует как клиент для компонента etcd (который хранит и извлекает состояние кластера) и 
компонента kubelet (который отслеживает и планирует новые поды).

Etcd: Хранит данные кластера. Действует как сервер всякий раз, когда к этим данным осуществляется доступ. 

Kubelet: действует как сервер, когда kube-apiserver связывается с ним для взаимодействия с рабочим узлом.

Пользователи: действуют как клиенты, взаимодействуя с кластером через kube-apiserver (используя kubectl и т. д.) 

Планировщик: компонент планировщика действует как клиент для компонента kube-apiserver, взаимодействуя с этим 
компонентом, чтобы определить, требуют ли какие-либо модули планирования, и, если это так, запланировать эти модули 
на соответствующем рабочем узле.

Kube-controller-manager: действует как клиент kube-apiserver, наблюдая за общим состоянием кластера через этот 
компонент и внося изменения, которые переводят кластер из желаемого состояния в текущее.

Kube-proxy: действует как клиент для kube-apiserver при проверке объявленных сопоставлений служб.

Генерация и реализация сертификатов в Kubernetes

Вот вкратце коммуникация API Kubernetes ; ее может быть много, но понимание этих компонентов и характера их 
коммуникации является ключом к ее защите. С этим фундаментальным пониманием вы можете начать создавать свои 
сертификаты. Сначала вы должны сгенерировать сертификат CA (Certificate Authority), который должен присутствовать на 
каждом компоненте для проверки полученных сертификатов. Затем каждому из компонентов, указанных выше, например 
клиенту или серверу, потребуется сгенерированный для них сертификат. Обратите внимание, что в случае kube-apiserver, 
который действует как сервер и клиент, вы можете использовать одни и те же сертификаты для всей коммуникации или 
создать отдельные сертификаты для коммуникации сервера, коммуникации клиента etcd и коммуникации клиента kubelet).

Шаг создания сертификата будет выполнен с использованием такого инструмента, как OpenSSL, чтобы сначала 
сгенерировать сертификат CA, а затем сгенерировать сертификат для каждого из компонентов, выполнив следующие шаги:

- Сгенерировать закрытый ключ: Пример команды -  openssl genrsa --out ca.key 2048
- Генерация CSR (запроса на подпись сертификата): Пример команды -openssl req --new --key ca.key --subj "/CN=192.168.
  0.100" --out ca.csr
- Генерация сертификата (подписание с помощью сертификата CA и закрытого ключа): Пример команды -openssl x509 --req 
  --in ca.csr --signkey ca.key --out ca.crt --days 365
- Некоторые дополнительные соображения необходимо учитывать, например, при работе с компонентами вроде kube-apiserver,
  имеющими альтернативные имена (чтобы мы могли подключаться к ним с помощью альтернативных маршрутов, таких как 
  kubernetes.default и kubernetes.default.svc и т. д.), но в целом эти шаги можно выполнить для генерации 
  сертификатов для каждого из компонентов. Для получения дополнительной информации о настройке перейдите по этой 
  ссылке.

После генерации сертификатов необходимо настроить соответствующие компоненты Kubernetes для использования. Это 
делается путем добавления этих конфигураций в файл YAML компонента . Вот пример блока кода из YAML-конфигурации 
kube-apiserver, как может выглядеть файл YAML с сгенерированными и определенными сертификатами:
```commandline
spec:
  containers:
  - command:
    - kube-apiserver
    - --*******************
    - --*******************
    - --client-ca-file=/var/lib/certs/ca.crt
    - --etcd-cafile=/var/lib/certs/etcd/ca.crt
    - --etcd-certfile=/var/lib/certs/apiserver-etcd-client.crt
    - --etcd-keyfile=/var/lib/certs/apiserver-etcd-client.key
    - --kubelet-client-certificate=/var/lib/certs/apiserver-kubelet-client.crt
    - --kubelet-client-key=/var/lib/certs/apiserver-kubelet-client.key
    - --proxy-client-cert-file=/var/lib/certs/front-proxy-client.crt
    - --proxy-client-key-file=/var/lib/certs/front-proxy-client.key
```

Оставаться в безопасности 

Реализация шифрования TLS таким образом реализует контрольные показатели безопасности CIS 1.2.24 - 27, еще больше 
укрепляя кластер. Однако обратите внимание, что когда эти сертификаты созданы и распространены, у них есть дата 
действия. Это означает, что в какой-то момент эти сертификаты придется ротировать. Как вы, вероятно, заметили, этот 
процесс может занять довольно много времени. Чтобы помочь с этим, Kubernetes создал API сертификатов Kubernetes . 
Этот API можно использовать для создания CSR и их утверждения для генерации сертификатов. В производственной среде 
эти действия, скорее всего, будут защищены RBAC, имеющим ClusterRoles для пользователей, создающих CSR, и для 
администраторов, одобряющих CSR.

значок ротации сертификата

Защита трафика API с помощью шифрования — определенно одна из самых сложных тем при обсуждении усиления кластера, и 
для ее освоения потребуется некоторое время и практический опыт. Сейчас просто важно понимать, что защита трафика 
API должна быть вашей первой линией обороны как инженера DevSecOps; включение шифрования — это один из способов, 
которым это делается путем защиты каждого из каналов связи с помощью шифрования сертификата TLS, что упрощается в 
дальнейшем с использованием API сертификатов . Другие способы защиты этого трафика включают авторизацию API, 
аутентификацию и эффективное использование контроллеров допуска. Подробнее о них далее!

### Ответьте на вопросы ниже
Какой компонент выполняет функции и «Сервера», и «Клиента»?
```commandline
Kube-apiserver
```
Какие контрольные показатели безопасности CIS будет реализовывать шифрование TLS?
```commandline
1.2.24 - 27
```

## Задание 6
Объяснение контролеров приема 

Мы только что рассмотрели, как можно защитить запросы к API в нашем кластере Kubernetes; однако, даже если запрос 
безопасен и аутентичен, возможно, мы захотим выполнить проверки того, что делает запрос, чтобы убедиться, что он не 
будет тратить ненужные ресурсы или реализовывать небезопасную практику. Для этого и нужны контроллеры допуска. Они 
перехватывают запрос после аутентификации/авторизации (но до создания объекта) и выполняют проверки, чтобы узнать, 
следует ли разрешить запрос. Представьте себе вышибалу в ночном клубе, проверяющего идентификатор потенциального 
клиента. Конечно, его идентификатор действителен, но, учитывая, что они не могут ходить по прямой, следует ли их 
впускать?

значок контроллера допуска


Контролеры допуска имеют две характеристики. Они могут быть одним, другим или обоими. Характеристики следующие:
- Изменение : Это означает, что контроллер допуска может изменять объект, связанный с запросом, который они 
  принимают. Например, контроллер допуска, который обеспечивает установку конфигурации pod на определенное значение. 
  Контроллер допуска получит запрос на создание pod и изменит (или мутирует) это значение конфигурации перед 
  сохранением.
- Проверка : это означает, что контроллер допуска проверяет данные запроса, чтобы одобрить или отклонить запрос. 
  Например, если контроллер допуска получает запрос на создание pod, но не имеет определенной метки, он отклоняется.
- Фактическая проверка, выполняемая контроллером допуска, зависит от того, какой это контроллер допуска. Вы можете 
  разделить контроллеры допуска на две группы: встроенные контроллеры допуска и пользовательские веб-перехватчики 
  контроллеров допуска. Давайте сначала рассмотрим встроенные контроллеры допуска. 

Встроенный

Kubernetes поставляется со многими встроенными контроллерами допуска, которые скомпилированы в двоичный файл 
kube-apiserver и, следовательно, могут быть настроены только администратором кластера. Некоторые примеры встроенных 
контроллеров допуска и их функции/проверки:

- AlwaysPullImages : этот контроллер допуска изменяет все новые поды и применяет политику ImagePullPolicy "Always". 
Как инженер DevSecOps , это тот тип AdmissionController, который вы хотите включить, поскольку он гарантирует, что 
поды всегда извлекают последнюю версию образа контейнера, одновременно смягчая атаки на цепочку поставок. Включение 
реализует CIS Security Benchmark 1.2.11.   

- EventRateLimit : Этот контроллер допуска помогает избежать проблемы, когда API Kubernetes переполняется запросами 
на сохранение новых событий. Установка этого предела реализует CIS Security Benchmark 1.2.9.

- ServiceAccount: Опять же, этот контроллер допуска настоятельно рекомендуется включить (самими Kubernetes); он 
гарантирует, что учетные записи служб по умолчанию создаются для модулей, в которых они не указаны. Это 
  предотвращает запуск модулей без связанной учетной записи службы, что может привести к повышению привилегий. 
  Включение реализует CIS Security Benchmark 1.2.13.

Эти встроенные контроллеры допуска реализуются путем редактирования YAML- файла kube-apiserver (после этого 
kube-apiserver необходимо перезапустить):
```commandline
apiVersion: v1
kind: Pod
metadata:
 name: kube-apiserver
 namespace: kube-system
spec:
 containers:
 - name: kube-apiserver
   command:
   - kube-apiserver
   - --admission-control=AlwaysPullImages
```

Веб-перехватчики контроллера приема 

Эти встроенные контроллеры допуска могут быть очень полезны для обеспечения соответствия вашего кластера 
предопределенным стандартам безопасности, которым следуют другие организации. Однако что, если ваша организация 
хочет внедрить пользовательские стандарты безопасности или специальные проверки развертывания pod, характерные для 
ее организации, например, синтаксис пространства имен? Это делается с помощью веб-перехватчиков контроллера допуска.

Вы определяете этот пользовательский веб-хук контроллера допуска, который будет содержать логику для проверки. При 
определении проверяющего веб-хука контроллера допуска логика определит условия допуска или отклонения. При  
определении изменяющего веб-хука контроллера допуска логика определит изменения, которые необходимо внести в 
объект/ресурс перед сохранением . Затем веб-хук контроллера допуска будет развернут как служба (или другой метод, 
который гарантирует, что у него есть конечная точка HTTP ). Теперь эти пользовательские веб-хуки контроллеров 
допуска не добавляются в kube-apiserver напрямую (из соображений безопасности/изоляции), а вызываются одним из двух 
встроенных контроллеров допуска (в зависимости от их логики) ValidatingAdmissionWebhook или MutatingAdmissionWebhook.

Оба этих встроенных контроллера допуска выступают в качестве посредника между пользовательским контроллером допуска 
и kube-apiserver. Например, если пользовательский контроллер допуска проверки был определен и представлен на 
конечной точке HTTP , эта конечная точка будет добавлена в ValidatingAdmissionWebhook (ресурс, который вы создаете)
вместе с любыми другими параметрами, такими как конфигурация TLS.

Когда Kubernetes затем получает запрос API (для создания, обновления или удаления ресурсов), он вызывает включенные 
веб-перехватчики допуска. URL-адреса конечных точек в этих веб-перехватчиках отправят запрос и дадут ответ API ( при 
проверке пропуска или отклонения с сообщениями об ошибках. При мутации, возможно, измененный объект.). Например, 
представьте, что вы определили пользовательский контроллер мутации допуска для обеспечения формата пространства имен;
вот как это может выглядеть.

схема веб-перехватчика контроллера допуска

```commandline
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: my-mutating-webhook
webhooks:
- name: my-mutating-webhook.example.com
  clientConfig:
    service:
      name: pod-name-admission-controller-service
      namespace: default
      path: "/mutate"
    caBundle: 
  admissionReviewVersions: ["v1"]
  rules:
  - operations: ["CREATE", "UPDATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
```

Контроллеры допуска — еще один инструмент в вашем арсенале DevSecOps . Их можно использовать для укрепления 
кластеров Kubernetes, чтобы гарантировать проверку авторизованных запросов и применение лучших практик безопасности.
### Ответьте на вопросы ниже
Какой тип контроллера допуска может изменять объект, связанный с принятым им запросом?
```commandline
Mutating
```
Какой встроенный контроллер допуска  помогает избежать проблемы, при которой API Kubernetes переполняется запросами 
на сохранение новых событий? 
```commandline
EventRateLimit
```
Что можно использовать, если ваша организация хочет внедрить специальные стандарты безопасности или специальные 
проверки развертывания модулей, характерные для ее организации?
```commandline
Admission Controller Webhooks 
```
Каковы имена двух встроенных контроллеров допуска, которые вызывают определенный веб-хук контроллера допуска? 
Формат: Answer1, Answer2
```commandline
ValidatingAdmissionWebhook, MutatingAdmissionWebhook
```

## Задание 7
Сети в Kubernetes

Теперь пришло время рассмотреть безопасность Kubernetes с точки зрения сети. Чтобы визуализировать потенциальные 
проблемы сетевой безопасности, которые могут возникнуть в нашем кластере Kubernetes, рассмотрим этот пример. Один из 
руководителей Kubernetes Laboratories хочет зарегистрировать результаты нашего последнего тестового объекта, поэтому 
они запускают веб-портал администратора (доступный через порт 80) и получают доступ к своей записи, отправляя запрос 
API (через порт 8080) в базу данных (через порт 27017).

диаграмма кластерной сети


Все модули в кластере Kubernetes развернуты в одной и той же виртуальной частной сети, чтобы они могли общаться друг 
с другом. Однако в некоторых случаях это необязательно или нежелательно, и нам следует укрепить наш кластер, удалив 
эти случаи. В приведенном выше примере наше веб-приложение должно общаться с API , однако веб-приложению не нужно 
общаться с базой данных. Затем этот канал связи следует ограничить. Это делается с помощью NetworkPolicy.

Ограничение взаимодействия между модулями с помощью сетевых политик

NetworkPolicy — это ресурс Kubernetes, который используется для ограничения сущности Kubernetes (службы/конечной 
точки), с которой может взаимодействовать pod. Они развертываются на уровне пространства имен, чтобы трафик можно 
было ограничить между ресурсами пространства имен (например, pod) или между самими пространствами имен. Вот пример 
того, как можно определить NetworkPolicy для ограничения трафика, чтобы база данных принимала только входящий трафик 
с порта 8080 ( API ):
```commandline
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: db-ingress-policy #policy name
spec:
  podSelector:
    matchLabels:
      app: database #label of app you want to protect
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api #label of app you want to allow traffic from
    ports:
    - protocol: TCP
      port: 8080 #port you want to allow traffic on
```

Мы определяем приложение, которое хотим защитить, в spec:PodSelector:matchLabels:appполе (оно будет соответствовать 
метке приложения, определенной в спецификации службы базы данных). Поскольку мы хотим пропускать трафик только в эту 
базу данных (а не из нее), мы устанавливаем поле spec:policyTypes просто на «Ingress». Однако, если бы мы разрешали 
и то, и другое, мы бы также включили «Egress». Наконец, в поле spec:ingress мы объявляем, с какой службы мы хотим 
принимать трафик и на каком порту (и по какому протоколу). Затем вы применяете этот NetworkPolicy YAML, как и любую 
другую конфигурацию с помощью команды kubectl apply -f <network-policy-name>.yaml, и вот вам! Вы ограничили сетевой 
трафик в вашей службе базы данных. Обратите внимание, что определение NetworkPolicies во всех пространствах имен 
реализует бенчмарк безопасности CIS 5.3.2.

С учетом NetworkPolicies вы теперь владеете большим количеством практик по усилению защиты кластера Kubernetes, 
чтобы гарантировать, что ваш кластер Kubernetes настроен безопасным образом с первого шага. Вы узнали о важности 
бенчмарков безопасности CIS, о том, как отслеживать соответствие требованиям в кластере, а также о том, как и почему 
используются некоторые из этих ключевых бенчмарков безопасности. Они продвинут вас далеко в вашем путешествии в 
качестве инженера DevSecOps. Теперь пришло время проверить их!

### Ответьте на вопросы ниже
Какой ресурс Kubernetes используется для ограничения взаимодействия между модулями?
```commandline
NetworkPolicy
```
Если бы у нас было запущенное приложение с меткой «база данных», в какое поле мы бы поместили эту метку, если бы мы 
хотели ограничить трафик для этого приложения?

```commandline
spec:PodSelector:matchLabels:app
```

## Задание 8
Наступил еще один день в Kubernetes Laboratories, и вы посещаете ежедневное совещание, на котором ваша команда будет 
обсуждать повестку дня. Доходит до того, что во время совещания раздаются невыполненные задачи/тикеты. Есть тикет, 
который нужно назначить; задача заключается в ограничении сетевого трафика в «backend-service2» в среде Kubernetes. 
Ваш менеджер считает, что это будет хорошей первой задачей для вас, и поэтому назначает вам тикет. Теперь у вас есть 
шанс показать, чему вы научились. Давайте приступим к работе над этим тикетом, хорошо?

Нажмите зеленую кнопку «Запустить машину», чтобы загрузить виртуальную машину. Подождите пару минут, пока 
виртуальная машина загрузится. Машина запустится в режиме разделенного экрана. Если виртуальная машина не видна, 
используйте синюю кнопку «Показать разделенный вид» в верхней части страницы.

В этом практическом занятии мы будем использовать minikube — инструмент, который настраивает среду Kubernetes на ПК. 
Установка vanilla minikube не поддерживает сетевые политики; это связано с тем, что CNI (Container Network Interface)
по умолчанию «Kindnet» не поддерживает их по умолчанию. Поэтому вместо этого мы будем работать с кластером, который 
использует другой CNI с именем «calico», который поддерживает сетевые политики. Чтобы запустить кластер с включенным 
CNI, выполните:

`minikube start --cni=calico`
Первое, что вам нужно сделать, это получить представление о местности. Выполните следующую команду, чтобы увидеть, 
что развернуто в этом кластере:


`kubectl get pods`
Примечание: процесс загрузки может занять минуту или две. Как только все три модуля будут запущены, можно переходить 
к следующему шагу! 

`kubectl get svc`
Здесь мы видим, что запущены 3 pod, все из которых имеют службу, предоставляющую их. В настоящее время 
веб-приложение может подключаться к службам backend-service1 и backend-service2. Давайте проверим это, выполнив 
следующую команду:

`kubectl exec ts-web-app-7bd668ddcb-zsdnw -- curl -I -m 2 backend-service2:8888 >/dev/null 2>&1 && echo "Connected to Service!" || echo "Cannot Connect to Service!"`
Это должно вернуть Connected to Service!, что означает, что этот pod веб-приложения может взаимодействовать с backend-service2. Мы также можем проверить подключение pod, запустив команду изнутри pod самостоятельно. Давайте попробуем это с backend-service1. Exec в pod с помощью: 

`kubectl exec backend-service1-86dbcf48bc-kz4b5 -it -- /bin/sh`
И выполните следующую команду изнутри модуля: 

`wget --spider --timeout=1 backend-service2:8888`
Он должен вернуться.remote file exists 

Теперь мы убедились, что и pod веб-приложения, и pod back-end-service1 могут взаимодействовать с back-end-service2. 
Однако в тикете, который вам был назначен, говорится, что единственный pod, который должен когда-либо 
взаимодействовать с backend-service2, — это pod backend-service1. Это означает, что нам нужно создать сетевую 
политику, которая разрешает трафик ОТ pod backend-service1 PODS ДО backend-service2 и будет отклонять весь остальной 
входящий трафик. Чтобы освежить в памяти, как выглядит NetworkPolicy YAML. Давайте посмотрим, как выглядит 
NetworkPolicy, которая отклоняет ВЕСЬ входящий трафик ДО backend-service2:
```commandline
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-ingress-backend-service2
spec:
  podSelector:
    matchLabels:
      app: backend-service2
  policyTypes:
  - Ingress

```
Давайте разберем это. Когда вы определяете поды, вы даете им «matchLabels», которые, как они звучат, являются 
метками, которые можно использовать для сопоставления пода. Под backend-service2 имеет метку «app:backend-service2», 
и поэтому может использоваться для идентификации этого пода. Затем мы можем указать эту метку в нашей NetworkPolicy, 
чтобы Kubernetes знал, для какого пода/службы мы хотим ограничить трафик. Затем мы сообщаем Kubernetes , какой это 
тип политики: Ingress (входящий трафик), Egress (исходящий трафик) или оба. В этом случае мы ограничиваем входящий 
трафик, то есть трафик, который получает под/служба. Теперь, когда это установлено, посмотрите, как будет выглядеть 
политика, необходимая для реализации вашей задачи по тикету:
```commandline
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backend-service1-ingress
spec:
  podSelector:
    matchLabels:
      app: replace-with-service2-label
  policyTypes:
  - replace-with-policy-type
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: replace-with-service1-label
    ports:
    - protocol: TCP
      port: replace-with-service2-listening-port
```
Теперь мы добавили немного больше в конец. После определения типа политики мы сообщаем Kubernetes , с какого pod мы 
хотели бы РАЗРЕШИТЬ входящий трафик, указав его метку приложения. Затем мы сообщаем Kubernetes , на какой порт мы 
хотели бы разрешить прием трафика. Другими словами, какой порт прослушивает backend-service2? Используя такие 
команды, как kubectl describe pod <pod-name> (для поиска меток pod) и kubectl get svc (для просмотра прослушиваемых 
портов служб), создайте файл с именем network-policy.yaml, используя приведенный выше пример, и заполните пробелы. 
Когда ваша сетевая политика будет готова, вы можете применить ее с помощью следующей команды:

`kubectl apply -f network-policy.yaml`
Теперь вы применили сетевую политику! Давайте проверим ее. Прежде всего, проверьте, что веб-приложение больше не 
может подключиться к backend-service2, повторно выполнив следующую команду:

`kubectl exec ts-web-app-7bd668ddcb-zsdnw -- curl -I -m 2 backend-service2:8888 >/dev/null 2>&1 && echo "Connected to Service!" || echo "Cannot Connect to Service!"`
Теперь это должно вернуть Cannot connect to service. Теперь войдите в модуль backend-service1 и выполните тестовую команду, как и раньше:

`kubectl exec backend-service1-86dbcf48bc-kz4b5 -it -- /bin/sh `


`wget --spider --timeout=1 backend-service2:8888`
Вы снова должны получить remote file exists сообщение о том, что вы завершили свой первый тикет в качестве инженера 
DevSecOps ! Поздравляем! После этого, чтобы завершить комнату, выполните следующую команду:

`kubectl describe networkpolicy allow-backend-service1-ingress`
Из вывода скопируйте Spec:строку вниз и вставьте ее в этот кодировщик base64. ПРИМЕЧАНИЕ: Убедитесь, что после 
последней строки нет дополнительных пробелов или дополнительных строк. Ответ на вопрос — политика кодировки base64!

### Ответьте на вопросы ниже
Что такое закодированная политика?
```commandline
U3BlYzoKICBQb2RTZWxlY3RvcjogICAgIGFwcD1iYWNrZW5kLXNlcnZpY2UyCiAgQWxsb3dpbmcgaW5ncmVzcyB0cmFmZmljOgogICAgVG8gUG9ydDogODg4OC9UQ1AKICAgIEZyb206CiAgICAgIFBvZFNlbGVjdG9yOiBhcHA9YmFja2VuZC1zZXJ2aWNlMQogIE5vdCBhZmZlY3RpbmcgZWdyZXNzIHRyYWZmaWMKICBQb2xpY3kgVHlwZXM6IEluZ3Jlc3M=
```

[>> вернуться на главную страницу](https://github.com/BEPb/tryhackme/blob/master/README.md)