[>> вернуться на главную страницу](https://github.com/BEPb/tryhackme/blob/master/README.md)

# Комната [Microservices Architectures](https://tryhackme.com/r/room/microservicearchitectures) 

Всего 7 заданий:
## Задание 1
Когда Kubernetes впервые был представлен в комнате Intro to Kubernetes , это было сделано с использованием контекста 
роста популярности архитектур микросервисов. То есть, вместо того, чтобы иметь приложение, построенное как единое 
целое (монолитная архитектура), они были разделены на контейнеризированные микросервисы. В этой комнате вы 
продолжите свой путь DevSecOps, узнав о проблемах безопасности при работе с архитектурами микросервисов и о том, 
как их можно решить в кластере Kubernetes. В этой комнате вы научитесь методам защиты архитектуры микросервисов, 
чтобы помочь Kubernetes Laboratories решить некоторые из своих проблем.


#### Предпосылки обучения 

Сначала убедитесь, что основы были охвачены, пройдя Intro to Kubernetes. Затем следует пройти две комнаты, которые 
следуют за этим: Cluster Hardening и K8s Best Security Practices. Если вы не знакомы с контейнеризацией в целом, то 
вам следует рассмотреть такие комнаты, как Intro to Containerisation, Intro to Docker и Container Hardening.

Цели обучения 
- Пользователь должен понимать стандарты безопасности Pod и допуск к безопасности Pod, а также амортизацию политик 
  безопасности Pod.
- Пользователь поймет проблемы, возникающие при работе с архитектурой микросервисов. 
- Пользователь поймет mTLS и то, как его можно использовать для обеспечения безопасности связи между микросервисами. 
- Пользователь поймет, что такое Service Mesh и как она решает проблемы, связанные с архитектурой микросервисов.
- Пользователь поймет архитектуру Istio Service Mesh и то, как ее можно использовать с архитектурой микросервисов 
  Kubernetes.

### Ответьте на вопросы ниже
Нажмите, чтобы перейти к следующему заданию!
### Ответ не требуется
```commandline
Ответ не нужен
```

## Задание 2
Давайте начнем эту комнату с прояснения распространенной точки путаницы. Один из способов защитить архитектуру 
микросервисов — это гарантировать, что модули, на которых запущены эти микросервисы, должны соответствовать 
определенным требованиям конфигурации безопасности, прежде чем они будут приняты в систему. Раньше это делалось 
путем определения PSP (Pod Security Policies). Этот термин — настоящее модное слово в мире безопасности Kubernetes; 
если ваше любопытство к этой теме заставило вас читать статьи или сообщения в блогах, то, скорее всего, вы часто 
видели упоминания PSP. В настоящее время нечасто упоминается то, что PSP с тех пор устарел (начиная с версии 
Kubernetes 1.21) и удален (начиная с версии Kubernetes 1.25). Эта задача направлена на то, чтобы сначала 
рассмотреть вопрос об устаревании PSP, чтобы прояснить любую путаницу относительно его отсутствия в этих комнатах, а 
затем определить замену Kubernetes для них. Этой заменой будут PSS (Pod Security Standards) и PSA (Pod Security 
Admission).         

#### Стандарты безопасности Pod 

Стандарты безопасности Pod в Kubernetes по сути определяют три уровня безопасности, которые вы хотите обеспечить. 
Эти уровни безопасности (довольно запутанно) называются 3 политиками в официальной документации Kubernetes. Эти 
уровни/политики описывают различные ограничения для различных вариантов использования. Давайте рассмотрим, что они 
собой представляют:
- **Привилегированный**: как следует из названия, это самая мягкая политика, которая не имеет ограничений, с самым 
  широким уровнем разрешений. Известные повышения привилегий разрешены с использованием этой политики, но они 
  преднамеренны. Вариант использования: для такой политики будет рабочая нагрузка на уровне системы или 
  инфраструктуры, которая управляется доверенным администратором кластера.

- **Baseline**: Базовая политика разработана для простоты принятия. Это минимально ограничительная политика, которая 
предотвращает известные эскалации привилегий. Определение pod по умолчанию будет разрешено с использованием этой 
  политики. Вариант использования: Эта политика предназначена для операторов приложений и разработчиков, работающих 
  с некритическими приложениями. Некоторым приложениям потребуются разрешения Baseline для запуска в качестве 
  «Ограниченных», поскольку последнее было бы слишком, ну, ограничительным.

- **Ограничено**: как это звучит, эта политика является крайне ограничительной и следует текущим лучшим практикам защиты 
pod. Однако это имеет свою цену в плане совместимости. Вариант использования: эта политика будет использоваться при 
  разработке и запуске критически важных для безопасности приложений.

#### PSS

Это 3 уровня/политики, которые могут быть реализованы, гарантируя, что созданные модули следуют предопределенному 
стандарту, так что вы можете быть спокойны, зная, что развертывается в вашем кластере. Только как эти стандарты 
реализуются?

Вход в Pod Security 

В комнате Kubernetes Best Security Practices мы рассмотрели 3 этапа, через которые проходит запрос API, прежде чем 
он будет принят/сохранен. Если вы помните, последний из этих 3 этапов — «Контроллеры допуска». Проверки, которые 
выполняются в отношении запроса в зависимости от того, какие из них были включены. Было упомянуто, что в Kubernetes 
есть много встроенных контроллеров допуска, одним из которых является контроллер допуска PodSecurity. Именно этот 
контроллер допуска обеспечивает соблюдение стандартов безопасности пода, изложенных в предыдущем разделе, и именно о 
нем идет речь, когда мы обсуждаем PSA (Pod Security Admission). Если PSS был установлен, например, для пространства 
имен, то контроллер допуска PodSecuirty будет запускаться при любых запросах на создание пода в этом пространстве 
имен. То, что контроллер допуска PodSecurity будет делать при нарушении этого стандарта, будет зависеть от 
выбранного режима. Существует 3 режима:
- **Принудительное применение**: если запрос на создание модуля нарушает политику, запрос будет отклонен.
- **Аудит**: Если запрос на создание pod нарушает политику, событие будет записано в журнал аудита. Однако запрос 
  будет разрешен, и pod будет создан.
- **Предупреждение**: Если запрос на создание pod нарушает политику, будет выдано предупреждение пользователю. 
  Однако запрос будет разрешен, и pod будет создан.


#### PSA и PSS в кластере  Kubernetes

Теперь, когда мы определили, как они работают, давайте посмотрим, как мы применим их к нашему кластеру Kubernetes. 
Давайте рассмотрим распространенный вариант использования: у нас есть некритическое приложение, работающее в 
«example-namespace», и мы хотим гарантировать, что все модули, работающие в этом пространстве имен, защищены от 
известных повышений привилегий, отклоняя все модули, которые не соответствуют этим стандартам. Чтобы включить эти 
стандарты безопасности модулей на уровне пространства имен, мы можем использовать метки. Kubernetes определяет метки,
которые вы можете задать, чтобы определить, какие из предопределенных стандартов безопасности модулей вы хотите 
использовать в пространстве имен и какой режим вы хотите использовать. Вот синтаксис метки:
`pod-security.kubernetes.io/<MODE>=<LEVEL>`
Например, если вы хотите установить базовый уровень и обеспечить его соблюдение:
`pod-security.kubernetes.io/enforce=baseline`
Необязательная метка также может быть включена, если вы хотите прикрепить версию политики, которая применяется (или 
проверяется/предупреждается), к версии, включенной в второстепенный релиз Kubernetes (или последний релиз). Это 
можно сделать с помощью:
`pod-security.kubernetes.io/enforce-version: v1.30`
Это формат метки, но как мы применим эту метку к нашему «example-namespace»? Мы можем сделать это с помощью команды 
Kubectl.
```commandline
Kubectl label –dry-run=server –overwrite ns example-namespace \ pod-security.kubernetes.io/enforce=baseline
```

> Примечание: опция dryrun не является обязательной, но это наилучшая практика, так как она позволяет вам проверить, 
> будут ли все запущенные модули в пространстве имен, которое вы маркируете, приняты с применением стандарта 
> безопасности. По сути, вы пытаетесь избежать случая, когда модуль приложения в этом пространстве имен, созданный 
> до маркировки, перезапускается, но отклоняется, поскольку не соответствует новым маркированным стандартам 
> безопасности. Если команда dryrun возвращает «<namespace> labelled» без каких-либо предупреждений, это означает, 
> что все модули, запущенные в этом пространстве имен, будут приняты с применением стандартов безопасности, которые 
> вы собираетесь применить. Затем команда будет запущена без флага dryrun для маркировки пространства имен.


Последнее замечание о Pod Security Admission. Мы только что рассмотрели, как обеспечить применение и соблюдение 
стандарта безопасности Pod на уровне пространства имен с помощью меток. Однако есть некоторые изменения конфигурации,
которые можно внести на уровне кластера. Как уже упоминалось, Kubernetes предоставляет нам PodSecurity Admission 
Controller, который обеспечивает соблюдение Pod Security Standards. Вы можете настроить этот Admission Controller 
(на главном узле) для внесения пользовательских изменений. Это включает значения по умолчанию, когда уровень режима 
не установлен, и исключения, например, аутентифицированные пользователи или пространства имен, которые должны быть 
освобождены от PodSecurity Admission Controller. Подробнее об этом можно узнать в документации Kubernetes.

### Ответьте на вопросы ниже
Какой уровень стандарта безопасности Pod вы бы использовали, чтобы гарантировать соблюдение лучших практик по 
усилению защиты кластера?
```commandline
Restricted
```
Какой уровень стандарта безопасности Pod допускает известные повышения привилегий?
```commandline
Privileged
```
Какой режим допуска Pod Security отклоняет запрос при нарушении политики?
```commandline
Enforce
```
Как будет выглядеть синтаксис метки, реализующей ограниченную политику?
```commandline
pod-security.kubernetes.io/enforce=restricted
```

## Задание 3
Визуализация архитектуры микросервисов 

Прежде чем мы углубимся в некоторые проблемы, которые могут возникнуть при построении архитектуры микросервисов, 
давайте представим, что мы под этим подразумеваем. Как уже говорилось, архитектура микросервисов подразумевает 
разделение частей приложения на микросервисы (которые работают как контейнеризированные рабочие нагрузки) вместо 
единого фрагмента кода (известного как монолитная архитектура). Давайте рассмотрим несколько примеров. Стриминговая 
компания, такая как Netflix (один из первых принявших этот стиль архитектуры), может решить разделить свое 
приложение на микросервисы, такие как: Streaming, Recommendations, Profiles и Catalogue Query. Интернет-магазин, 
такой как Amazon, может иметь микросервисы, такие как WebApp, Basket, Orders и Product Query. Вот как настроена 
архитектура микросервисов здесь, в Kubernetes Laboratories: Пример архитектуры микросервиса
#### Проблемы архитектуры микросервисов

Обеспечение безопасности связи между модулями


Возможно, вы помните, в комнате Cluster Hardening мы обсуждали, как ограничить связь между подами с помощью сетевых 
политик. Теперь мы обсудим, как защитить связь между подами. Типичная архитектура микросервисов будет настроена 
следующим образом: клиент подключается к кластеру Kubernetes с помощью HTTPS, обращается к балансировщику нагрузки, 
который затем пересылает запрос на контроллер входящего трафика также с помощью HTTPS. Вероятно, кластер также будет 
защищен брандмауэром. Однако с этого момента, как только мы окажемся внутри кластера, связь между подами будет 
осуществляться с помощью HTTP или какого-либо другого незащищенного протокола. Другими словами, сам кластер защищен, 
но внутри него есть незащищенный, незашифрованный трафик.


Небезопасная внутренняя коммуникация

Это имеет определенные последствия для локальной сети; это не будет соответствовать лучшим практикам, но последствия 
будут хуже, если вы рассмотрите развертывание в облаке, чем часто являются архитектуры микросервисов. Поставщики 
облачных услуг предоставляют несколько AZ (зон доступности) для обеспечения бесперебойной работы вашего приложения; 
если одна AZ выходит из строя, другая остается в рабочем состоянии. Из-за этого некоторые службы в вашем кластере 
могут работать в разных AZ, что означает, что незашифрованная связь между службами может быть перехвачена 
злоумышленником. Именно по этой причине трафик между службами должен быть зашифрован с использованием mTLS.

Связь от AZ до AZ

**mTLS (Mutual Transport Layer Security)** обеспечивает взаимную аутентификацию, гарантируя, что обе стороны соединения 
аутентифицированы с использованием сертификатов. Как вы знаете, при использовании TLS (Transport Layer Security) 
сервер имеет сертификат TLS и пару открытого/закрытого ключа. Однако у клиента их нет. В mTLS, с другой стороны, и 
клиент, и сервер имеют сертификат и аутентификацию с использованием пары открытого/закрытого ключа. Еще одним 
примечательным отличием является то, что в mTLS организация, которая его реализует, действует как свой собственный 
CA (центр сертификации) вместо того, чтобы внешняя организация проверяла его личность. Вот визуализация того, как 
работает mTLS, и этапы соединения, которые происходят между клиентом и сервером. Шаги, выделенные звездочкой, 
являются дополнительными шагами в mTLS (по сравнению с TLS).

mTLS-коммуникация

Многое нужно учесть

Давайте рассмотрим этот пример архитектуры микросервисов. Каждый из наших микросервисов работает внутри модуля. У 
каждого будет своя собственная бизнес-логика, также известная как функциональность, которая является его целью в 
нашем приложении. Затем наши микросервисы будут общаться друг с другом; например, один из наших сотрудников может 
подключиться к службе WebApp, которая будет общаться со службой Results, которая, после регистрации, будет общаться 
с DB. Для этого каждому микросервису необходимо будет знать конечную точку всех микросервисов, с которыми он 
общается; это известно как конфигурация связи. Выше мы обсуждали важность обеспечения безопасности связи между 
модулями с помощью mTLS; для этого микросервису также необходимо включить логику безопасности. Чтобы микросервис 
был надежным, он должен будет включать некоторую логику повтора, которая повторяет попытку соединения, если 
микросервис, с которым он общается, не работает, например. Помимо всего этого, мониторинг сервисов часто необходим 
для получения бизнес-информации об использовании и производительности микросервисов, а также для отслеживания данных,
которые могут быть полезны в контексте устранения неполадок. Соберите все это вместе, и внезапно ваш микросервис не 
будет выглядеть таким уж микро.

Значок занятого стручка

Вся эта небизнес-логика должна быть добавлена в каждый микросервис/приложение, что может привести к тому, что 
разработчики будут тратить все свое время на эти конфигурации вместо фактической разработки самого приложения. 
Вдобавок ко всему, ручная настройка этой небизнес-логики, иногда в разных командах (с разными командами 
разработчиков, назначенными на определенные микросервисы), может привести к неправильным конфигурациям, что особенно 
важно в контексте безопасности. Вот где вступают в дело Service Meshes.

### Ответьте на вопросы ниже
Альтернативой какому стилю архитектуры является микросервисная архитектура?
```commandline
Monolithic
```
Проблема микросервисных архитектур заключается в том, что взаимодействие между сервисами обычно...
```commandline
Unencrypted
```
Решением вышеуказанной проблемы было бы использование аутентификации обеих сторон соединения?
```commandline
mTLS
```

## Задание 4
Ответ на наши проблемы с микросервисами

Все проблемы, изложенные в предыдущей задаче, можно решить с помощью одного удобного и эффективного решения: 
сервисной сетки. Сервисная сетка — это выделенный инфраструктурный уровень, который можно использовать для контроля 
и управления коммуникацией между службами. В этой задаче будет объяснено, как это делается и как он решает проблемы, 
изложенные в предыдущей задаче. Поистине, лучший друг инженера DevSecOps. Учитывая выявленную проблему, разработка 
всей этой дополнительной логики и конфигураций поверх бизнес-логики на основе сервиса между службами может 
потребовать много работы. Разве не имело бы тогда смысла отделить бизнес-логику микросервиса от всей остальной 
логики и конфигураций и обрабатывать ее отдельно и многократно во всех микросервисах? Именно этого можно добиться с 
помощью сервисной сетки.

#### Разделение бизнес-логики

Как это достигается?

Сервисная сетка достигает этого, извлекая всю небизнес-логику и конфигурации и запуская их в своем собственном 
прокси параллельно с микросервисом, называемом sidecar. Sidecar вызывает в воображении образы тех мотоциклов с 
небольшим дополнением, прикрепленным к его боку; по сути, это то, как мы определяем sidecar в технологиях. Мотоцикл 
является основным приложением, а sidecar — это служба или процесс, развернутый параллельно, который поддерживает 
основное приложение. В этом случае sidecar используется в качестве прокси. Прокси обычно используются в сфере 
безопасности, и регулярно используемый пример — это доступ сотрудника к веб-странице через свою рабочую станцию. 
Этот запрос сначала будет получен веб-прокси их компании; он должен будет пройти проверки безопасности прокси, 
прежде чем будет перенаправлен на веб-сервер. Затем сервер вернет страницу веб-прокси, где ей снова нужно будет 
пройти проверки безопасности, прежде чем она будет окончательно перенаправлена сотруднику.

Значок прокси-сервера Sidecar

В сервисной сетке эти прокси-серверы sidecar используются, образуя свой собственный инфраструктурный уровень, где 
запросы между микросервисами могут маршрутизироваться. Другими словами, вся логика безопасности, конфигурация связи, 
логика повтора, мониторинг сервисов и трассировка выполняются этим прокси-сервером sidecar. Они называются sidecar, 
потому что работают вместе с микросервисом, который содержит фактическую бизнес-логику. Эти взаимосвязанные 
прокси-серверы sidecar образуют ячеистую сеть.

Значок ячеистой сети

Какую выгоду получают инженеры DevSecOps

Примеры архитектур микросервисов, обсуждавшиеся в предыдущих задачах, являются очень примитивными примерами. В 
действительности крупные организации могут иметь очень сложные архитектуры с многочисленными микросервисами. 
Добавление еще одного микросервиса или другого экземпляра существующего микросервиса может еще больше усложнить 
архитектуру дополнительными каналами связи и конфигурациями безопасности, и по мере роста архитектуры поиск 
первопричины проблем может становиться все сложнее и сложнее. Сервисная сетка становится лучшим другом инженера 
DevSecOps, извлекая все это, не только обеспечивая согласованность и безопасность в коммуникации между сервисами, 
но и фиксируя метрики производительности, что может помочь обеспечить надежную архитектуру (например, среднее время, 
необходимое для перезапуска сервиса, может быть учтено при попытке повторной попытки). Устранение необходимости 
настраивать всю небизнес-логику для каждого приложения и выполнение всего этого в прокси-сервере sidecar также 
делает приложения более масштабируемыми.

Значок положительных результатов DevSecOps

Сервисные сетки — это выигрыш для всех; с точки зрения разработчика они могут сосредоточиться на разработке 
бизнес-логики приложения, не беспокоясь о необходимости встраивать такие вещи, как конфигурация связи и логика 
безопасности в приложение. С точки зрения безопасности вы можете быть уверены, что сервисная сетка управляет 
безопасным соединением mTLS между службами. По этой причине при управлении архитектурой микросервисов в Kubernetes 
всегда следует рассматривать сервисную сетку.

### Ответьте на вопросы ниже
Какую логику отделяет Service Mesh от остальной?
```commandline
Business
```
Остальные выделены в отдельный прокси-сервер, который работает вместе с модулем приложения, известным как?
```commandline
Sidecar
```

## Задание 5
Истио спешит на помощь 

Мы рассмотрели, что такое Service Mesh и как именно он может помочь инженеру DevSecOps защитить архитектуру 
микросервисов; теперь мы рассмотрим популярную реализацию Service Mesh, Istio. По сути, Service Mesh — это 
концепция, а Istio — одна из технологий, которую мы можем использовать для ее достижения (другие реализации включают 
Linkerd и Hashicorp Consul). Популярный выбор для реализации Service Mesh в архитектуре микросервисов Kubernetes, 
он имеет модель безопасности «безопасность по умолчанию», что делает его идеальным для инженеров DevSecOps, 
желающих развертывать приложения, ориентированные на безопасность. В этой задаче мы разберем архитектуру Istio, 
чтобы дать вам лучшее понимание того, как Service Mesh работает в кластере Kubernetes. Архитектура Istio логически 
разделена на две части: плоскость данных и плоскость управления. Теперь мы дадим определение каждому из этих 
разделов и принципам их работы, но на высоком уровне плоскость данных представляет собой набор интеллектуальных 
прокси-серверов, развернутых в качестве дополнительных модулей, а плоскость управления отвечает за управление и 
настройку этих прокси-серверов.

Значок «Истио спешит на помощь»

#### Прокси-серверы Envoy (плоскость данных) 

В предыдущей задаче упоминалось, что в сервисной сетке вся небизнес-логика извлекается и запускается как сторонний 
прокси-сервер параллельно сервису. В Istio (и многих других реализациях сервисной сетки) это достигается с помощью 
Envoy. Envoy — это высокопроизводительный пограничный и сервисный прокси с открытым исходным кодом, который 
используется в этом случае для управления входящим и исходящим трафиком между сервисами. Эти 
прокси-серверы-посредники взаимодействуют с сетевым трафиком и позволяют использовать такие функции, как шифрование 
mTLS между сервисами, как было настроено. Связь между этими прокси-серверами-посредниками формирует плоскость данных,
одну из двух архитектурных плоскостей в Istio.

Диаграмма плоскости данных

#### Истиод (Плоскость управления)

Istiod — это название компонента, который составляет Control Plane. Istiod позволяет обнаруживать службы, 
настраивать их и управлять сертификатами. Этот компонент отвечает за принятие высокоуровневых правил маршрутизации, 
которые были определены, и превращение их в конфигурации, специфичные для Envoy. Затем эти конфигурации внедряются в 
прокси-серверы sidecar во время выполнения. Этот компонент также может абстрагировать механизмы обнаружения служб, 
специфичные для платформы (например, Kubernetes), и преобразовывать их в стандартный формат, который может 
использоваться API Envoy. Таким образом, когда в вашем кластере Kubernetes запускается новая служба, плоскость 
управления обнаружит и внедрит прокси-сервер sidecar для работы вместе с ней.

Стоит отметить, что до версии 1.5 плоскость управления Istio состояла из нескольких компонентов (Pilot, Citadel, 
Mixer и Gallery). Однако теперь все эти компоненты были объединены в один компонент Istiod. Это упростило для 
пользователей настройку/эксплуатацию. Я указываю на это, потому что некоторые другие ресурсы устарели и ссылаются на 
плоскость управления, состоящую из этих компонентов.

Диаграмма плоскости управления

Собираем все вместе 

Объединяя Data Plane и Control Plane, мы получаем полную архитектуру Istio. Control Plane отвечает за конфигурацию, 
обнаружение и сертификаты и распространяет все запущенные службы с помощью envoy sidecar proxy, сети, которая 
взаимодействует с сетчатым трафиком, формируя data plane.

Архитектурная схема Istio

### Ответьте на вопросы ниже
В этом задании мы рассмотрели реализацию Service Mesh под названием «Как?»
```commandline
Istio
```
Что используется для достижения прокси-серверов в этой реализации Service Mesh?
```commandline
Envoy
```
Как называется эта область архитектуры, где прокси-серверы взаимодействуют со службами (и другими прокси-серверами)?
```commandline
Data Plane
```
Как называется компонент, входящий в состав плоскости управления?
```commandline
Istiod
```

## Задание 6
Начиная

Прежде чем начать с введения, хорошей идеей будет загрузить VM и кластер minikube. Нажмите зеленую кнопку «Запустить 
машину» и подождите 2 минуты, пока она загрузится. Машина запустится в режиме разделенного экрана. Если VM не видна, 
используйте синюю кнопку «Показать разделенный вид» в верхней части страницы. После загрузки выполните следующую 
команду, чтобы запустить кластер minikube:

Запуск Minikube
```commandline
thm@k8s$ minikube start
```
А теперь перейдем к уроку.

Это уже третья неделя вашего пребывания в Kubernetes Laboratories; медленно, но верно ваши навыки DevSecOps растут, 
и команда доверяет вам все больше и больше работы. Во время утреннего совещания было упомянуто, что есть 
невыполненный тикет по безопасности, окружающей архитектуру микросервисов Kubernetes Laboratories. В этом тикете 
объясняется, что член команды DevSecOps должен провести обзор, изменив некоторые конфигурации и посоветовав команде 
разработчиков, как настраивать их микросервисы в будущем.

Проверка конфигурации

Загрузив кластер minikube, начнем расследование. Для начала проверим, установлен ли Istio в этом кластере Kubernetes 
. Это можно сделать, проверив, существует ли пространство имен istio-system. Это можно проверить с помощью следующей 
команды:

Проверка пространств имен
```commandline
thm@k8s$ kubectl get namespaces
```
Здесь мы видим, что присутствует пространство имен "istio-system", что означает, что Istio установлен в кластере. В 
этом пространстве имен pod будет запускать компонент Istiod (он же плоскость управления).

Плоскость управления

Теперь, когда мы знаем, что Istio установлен в кластере, следующее, что мы хотим убедиться как инженер DevSecOps, 
это то, что он используется правильно. Назначенный нам тикет просит нас просмотреть микросервисы, работающие в 
пространстве имен по умолчанию. Давайте продолжим расследование, выполнив следующую команду, чтобы проверить статус 
модулей, работающих в пространстве имен по умолчанию:

Проверка стручков
```commandline
thm@k8s$ kubectl get pods
```
Выполнение этой команды должно вернуть что-то вроде следующего вывода:

Пример терминала
```commandline
thm@k8s$
NAME                                    READY   STATUS    RESTARTS      AGE
database-5c6bcbb7d8-ht8pg               1/1     Running   1 (15m ago)   2d1h
products-7f5984db48-z9rst               1/1     Running   2 (15m ago)   2d3h
results-674478647d-s8ppb                1/1     Running   2 (15m ago)   2d3h
subject-registration-666cd768cb-rgprq   1/1     Running   2 (15m ago)   2d3h
test-chambers-6bff7bc878-zp7wm          1/1     Running   2 (15m ago)   2d3h
web-server-8569bb59bd-48gcr             1/1     Running   2 (15m ago)   2d3h
```

Примечание : если статус — «Ошибка», подождите еще 1–2 минуты, пока модули не отобразятся как «Работает».

Включение прокси- инъекции

Здесь мы видим каждый из модулей, работающих в пространстве имен по умолчанию. В столбце «ГОТОВО» мы видим 1/1 рядом 
со всеми запущенными модулями. Это относится к тому, сколько контейнеров запущено внутри модуля. Если вы помните из 
нашего урока, когда сетка служб настроена правильно, внутри модуля должны работать два контейнера (один запускает 
приложение, а другой — прокси-сервер sidecar). Из этого мы можем определить, что внедрение прокси-сервера Istio не 
включено. Это автоматическое внедрение прокси-сервера sidecar в запущенные модули приложений. Мы можем включить это 
с помощью метки Kubernetes (при условии, что, как мы подтвердили, Istio установлен в кластере Kubernetes ). Вот 
команда, которую мы будем использовать для маркировки пространства имен по умолчанию, чтобы все модули, запущенные в 
этом пространстве имен, автоматически внедрялись с контейнером прокси-сервера sidecar:

Давать возможность Прокси Инъекция
```commandline
thm@k8s$ kubectl label namespace default istio-injection=enabled
```
С этим пространством имен, помеченным для автоматического внедрения прокси, мы теперь хотим перезапустить все модули,
работающие в пространстве имен по умолчанию. Чтобы сделать это проще, есть манифест yaml (в каталоге /home/ubuntu), 
содержащий конфигурацию для работающих модулей в этом пространстве имен. Мы можем перезапустить все, работающее в 
этом пространстве имен, просто удалив и применив этот манифест с помощью следующих двух команд (когда они находятся 
в каталоге /home/ubuntu):

Перезапуск модулей
```commandline
thm@k8s$ kubectl delete -f microservice-manifest.yaml 

thm@k8s$ kubectl apply -f microservice-manifest.yaml

```
Подождав некоторое время, пока модули снова заработают, с помощью kubectl get pods, мы должны увидеть следующее 
состояние работы модулей:

Пример терминала
```commandline
thm@k8s$ kubectl get pods
NAME                                    READY   STATUS    RESTARTS   AGE
database-5c6bcbb7d8-vzgct               2/2     Running   0          7m12s
products-7f5984db48-hzndf               2/2     Running   0          7m12s
results-674478647d-9qjvs                2/2     Running   0          7m12s
subject-registration-666cd768cb-tgwsl   2/2     Running   0          7m12s
test-chambers-6bff7bc878-k65lq          2/2     Running   0          7m12s
web-server-8569bb59bd-r52pn             2/2     Running   0          7m12s
```
Теперь у нас есть sidecar proxy-контейнер, работающий в каждом из наших pod в пространстве имен. Если вам интересно, 
вы можете использовать команду, kubectl describe pod <pod-name> чтобы получить больше подробностей о 
proxy-контейнере Istio.

Плоскость данных

Обеспечение соблюдения mTLS-трафика

Теперь, когда мы включили автоматическое внедрение прокси, следующее, что мы хотим рассмотреть как инженер DevSecOps,
— это конфигурация mTLS. Это обеспечение безопасности всего нашего внутреннего трафика. Теперь Istio автоматически 
настраивает сайдкары рабочей нагрузки для использования mTLS при вызове других рабочих нагрузок. Однако по умолчанию 
Istio настраивает mTLS в разрешающем режиме. Разрешающий режим позволяет службе получать как трафик mTLS, так и 
текстовый (незашифрованный) трафик. Это режим по умолчанию, поскольку он подходит для многих вариантов использования,
когда крупные организации не могут обновить всю свою среду одновременно, поэтому службы должны иметь возможность 
получать как текстовый, так и mTLS-трафик. Однако в нашем случае мы обновили всю эту среду, поэтому мы не хотим 
использовать разрешающий режим. Мы хотим строгий режим, который разрешает только трафик mTLS. Istio обрабатывает это 
с помощью «Политик аутентификации», где мы определяем, какой уровень аутентификации нам нужен.

Эти политики позволяют нам определять политики аутентификации для определенных ресурсов. Например, у нас есть 
приложение, которое обрабатывает особенно чувствительный трафик. Мы могли бы создать политику аутентификации, 
например, чтобы гарантировать, что разрешен только трафик mTLS:
```commandline
auth.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: "sensitive-peer-policy"
  namespace: "example-namespace"
spec:
  selector:
    matchLabels:
      app: sensitive-app
  mtls:
    mode: STRICT
```
Учитывая, что мы хотим применить нашу политику аутентификации ко всем модулям в пространстве имен, мы можем 
структурировать ее следующим образом:
```commandline
auth.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: default
spec:
  mtls:
    mode: STRICT
```
Скопируйте содержимое файла выше и создайте файл с именем "auth.yaml" с его содержимым. Затем вы можете применить 
эту политику аутентификации с помощью kubectl:

Применить политику аутентификации
```commandline
thm@k8s$ kubectl apply -f auth.yaml
```
После этого наша сервисная сетка настроена, а внутренний трафик защищен. Мы можем пометить наш тикет как завершенный 
и сообщить команде разработчиков о внесенных изменениях. С завершением третьей недели в Kubernetes Laboratories вы 
почти прошли свой испытательный срок и готовы надеть звание инженера DevSecOps. Выполните следующую команду, чтобы 
описать политику аутентификации, которую вы только что создали, и отправьте значение, содержащееся в поле версии API 
, чтобы выполнить эту задачу:

Опишите политику аутентификации
```commandline
thm@k8s$ kubectl describe peerauthentication default
```
### Ответьте на вопросы ниже
Какое значение содержится в поле версии API при описании политики аутентификации?
```commandline
security.istio.io/v1
```

## Задание 7
Пройдя эту комнату, вы расширили свою базу знаний DevSecOps, получив более глубокое понимание архитектур 
микросервисов, основополагающего термина в Kubernetes, и методов, которые можно использовать для их защиты. Теперь 
ваш арсенал Kubernetes становится довольно богатым. Давайте повторим то, что мы рассмотрели в этой комнате, чтобы 
сохранить знания в тайне. В этой комнате вы узнали:

- Стандарты безопасности модулей определяют три уровня безопасности модулей: привилегированный, базовый и ограниченный. 
- Вышеуказанные стандарты обеспечиваются Pod Security Admisson, который имеет три режима: обеспечение соблюдения, 
  аудит и предупреждение.
- Создание архитектуры микросервисов сопряжено с такими проблемами, как обеспечение безопасности связи между модулями 
  и модулей приложений, заполненных конфигурацией/логикой.
- Решение вышеупомянутых проблем можно найти в Service Meshes, которые разделяют бизнес-логику приложения и 
  запускают все остальное в дополнительном прокси-сервере одновременно. 
- Istio — это реализация Service Mesh, состоящая из двух частей: плоскости управления и плоскости данных.
- Istio можно установить в кластер Kubernetes, включить автоматическое внедрение прокси-сервера и настроить политики 
  аутентификации для обеспечения безопасной внутренней связи.
- И с этим вы завершили еще одну комнату Kubernetes и стали на один шаг ближе к мастерству Kubernetes. Выйдите из 
  системы после очередного тяжелого дня в Kubernetes Laboratories. 

### Ответьте на вопросы ниже
Все готово!
```commandline
Ответ не нужен
```
[>> вернуться на главную страницу](https://github.com/BEPb/tryhackme/blob/master/README.md)